{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1672ec65-13a6-4fe8-901a-a1c8f3c51c08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Generate All Bronze / Silver / Gold Notebooks (Workspace)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Configuration\n",
    "# ----------------------------------------------------------------------\n",
    "# Base workspace path (where notebooks will be created)\n",
    "BASE = \"/Users/dhruvil@uciny.com/ShopFast/Layers\"\n",
    "BRONZE = f\"{BASE}/Bronze\"\n",
    "SILVER = f\"{BASE}/Silver\"\n",
    "GOLD = f\"{BASE}/Gold\"\n",
    "\n",
    "# Get Databricks workspace URL and token\n",
    "ctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "workspace_url = ctx.apiUrl().get()\n",
    "token = ctx.apiToken().get()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Notebook template\n",
    "# ----------------------------------------------------------------------\n",
    "TEMPLATE = \"\"\"# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # {title}\n",
    "# MAGIC\n",
    "# MAGIC **Layer**: {layer}  \n",
    "# MAGIC **Target table(s)**: `{tables}`  \n",
    "# MAGIC **Description**: {desc}  \n",
    "# MAGIC **Generated**: {ts}\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 1. Setup & Imports\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 2. Read Source Data\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# TODO: Implement source data reading\n",
    "# Example:\n",
    "# df = spark.read.format(\"...\").load(\"...\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 3. Data Quality & Validation\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# TODO: Add data quality checks\n",
    "# Example: Check for nulls, duplicates, schema validation\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 4. Write to Delta Table\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# TODO: Write to Delta table\n",
    "# Example:\n",
    "# df.write \\\n",
    "#   .format(\"delta\") \\\n",
    "#   .mode(\"append\") \\\n",
    "#   .option(\"mergeSchema\", \"true\") \\\n",
    "#   .saveAsTable(\"{tables}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## 5. Logging & Monitoring\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# TODO: Add logging and alerts\n",
    "# Record counts, execution time, data quality metrics\n",
    "\"\"\"\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. Notebook definitions\n",
    "# ----------------------------------------------------------------------\n",
    "NOTEBOOKS = {\n",
    "    \"Bronze\": [\n",
    "        (\"b01_bronze_web_orders_ingestion\", \"Ingest Web Orders (PostgreSQL CDC)\", \"bronze_web_orders\", \"CDC from PostgreSQL using Debezium/Fivetran\"),\n",
    "        (\"b02_bronze_web_order_items_ingestion\", \"Ingest Web Order Items\", \"bronze_web_order_items\", \"Line items from web orders\"),\n",
    "        (\"b03_bronze_web_inventory_ingestion\", \"Ingest Web Inventory Snapshot\", \"bronze_web_inventory\", \"Real-time inventory view from website DB\"),\n",
    "        (\"b04_bronze_web_products_ingestion\", \"Ingest Product Catalog\", \"bronze_web_products\", \"Master product data with pricing & suppliers\"),\n",
    "        (\"b05_bronze_app_orders_ingestion\", \"Ingest Mobile App Orders (MongoDB)\", \"bronze_app_orders\", \"Change streams from MongoDB Atlas\"),\n",
    "        (\"b06_bronze_app_order_items_ingestion\", \"Ingest Mobile Order Items\", \"bronze_app_order_items\", \"Flattened array items\"),\n",
    "        (\"b07_bronze_app_cart_events_ingestion\", \"Ingest Cart Events\", \"bronze_app_cart_events\", \"Add/remove events for inventory holds\"),\n",
    "        (\"b08_bronze_app_inventory_sync_ingestion\", \"Ingest App Inventory Cache\", \"bronze_app_inventory_sync\", \"30-min sync cycle\"),\n",
    "        (\"b09_bronze_wh_east_inventory_ingestion\", \"Ingest East Warehouse CSV\", \"bronze_wh_east_inventory\", \"Daily CSV via AutoLoader\"),\n",
    "        (\"b10_bronze_wh_west_inventory_ingestion\", \"Ingest West Warehouse CSV\", \"bronze_wh_west_inventory\", \"Pipe-delimited, schema-on-read\"),\n",
    "        (\"b11_bronze_wh_central_inventory_ingestion\", \"Ingest Central Warehouse CSV\", \"bronze_wh_central_inventory\", \"Detailed export with damaged & in-transit\"),\n",
    "        (\"b12_bronze_pos_manhattan_inventory_ingestion\", \"Ingest Manhattan POS Inventory (API)\", \"bronze_pos_manhattan_inventory\", \"REST polling every 5 min\"),\n",
    "        (\"b13_bronze_pos_la_transactions_ingestion\", \"Ingest LA POS Transactions (Kafka)\", \"bronze_pos_la_transactions\", \"Real-time Kafka stream\"),\n",
    "        (\"b14_bronze_pos_la_transaction_items_ingestion\", \"Ingest LA Transaction Items\", \"bronze_pos_la_transaction_items\", \"Line items with inventory impact\"),\n",
    "        (\"b15_bronze_pos_la_inventory_adjustments_ingestion\", \"Ingest LA Inventory Adjustments\", \"bronze_pos_la_inventory_adjustments\", \"Damage/theft/return events\"),\n",
    "    ],\n",
    "    \"Silver\": [\n",
    "        (\"s01_silver_orders_unification\", \"Unify Orders (Web + Mobile)\", \"silver_orders\", \"Harmonise schema, dedupe, SCD prep\"),\n",
    "        (\"s02_silver_order_items_unification\", \"Unify Order Items\", \"silver_order_items\", \"Standard fields across channels\"),\n",
    "        (\"s03_silver_inventory_unified_reconciliation\", \"Reconcile Inventory Across Sources\", \"silver_inventory_unified\", \"Merge 5 sources, calculate ATP\"),\n",
    "        (\"s04_silver_inventory_discrepancies_detection\", \"Detect Inventory Discrepancies\", \"silver_inventory_discrepancies\", \"Negative qty, reserved > physical, etc.\"),\n",
    "        (\"s05_silver_products_master_harmonization\", \"Harmonise Product Master\", \"silver_products\", \"SCD Type-2 prep, supplier mapping\"),\n",
    "        (\"s06_silver_transactions_unification\", \"Unify Transactions (All Channels)\", \"silver_transactions\", \"Web, app, POS sales in one table\"),\n",
    "        (\"s07_silver_transaction_items_unification\", \"Unify Transaction Line Items\", \"silver_transaction_items\", \"With inventory impact\"),\n",
    "        (\"s08_silver_inventory_movements_consolidation\", \"Consolidate Inventory Movements\", \"silver_inventory_movements\", \"Sales, returns, transfers, adjustments\"),\n",
    "        (\"s09_silver_data_quality_checks\", \"Run Data-Quality Suite\", \"silver_data_quality_checks\", \"Great Expectations + custom rules\"),\n",
    "        (\"s10_silver_late_arriving_data_handling\", \"Handle Late-Arriving Data\", \"silver_late_arriving_data\", \"Re-process delayed warehouse CSVs\"),\n",
    "    ],\n",
    "    \"Gold\": [\n",
    "        (\"g01_dim_product_scd_type2\", \"Build Dim Product (SCD Type 2)\", \"dim_product\", \"Track name, category, supplier changes\"),\n",
    "        (\"g02_dim_product_price_history_scd\", \"Build Price History (SCD Type 2)\", \"dim_product_price_history\", \"List price, cost, promotions\"),\n",
    "        (\"g03_dim_location_master\", \"Build Dim Location\", \"dim_location\", \"Warehouses, stores, online\"),\n",
    "        (\"g04_dim_date_calendar\", \"Build Date Dimension\", \"dim_date\", \"Holidays, fiscal calendar\"),\n",
    "        (\"g05_dim_customer_scd_type2\", \"Build Dim Customer (SCD Type 2)\", \"dim_customer\", \"Segment, tier, LTV changes\"),\n",
    "        (\"g06_fact_inventory_snapshot_daily\", \"Build Fact Inventory Snapshot\", \"fact_inventory_snapshot\", \"Point-in-time ATP, value, coverage\"),\n",
    "        (\"g07_fact_sales_transactions_lineitem\", \"Build Fact Sales Transactions\", \"fact_sales_transactions\", \"Line-item grain, margin, channel\"),\n",
    "        (\"g08_fact_sales_velocity_rolling\", \"Build Sales Velocity & Forecast\", \"fact_sales_velocity\", \"7/30-day avg, stockout prediction\"),\n",
    "        (\"g09_fact_stockout_events_impact\", \"Build Fact Stockout Events\", \"fact_stockout_events\", \"Revenue loss, root cause, resolution\"),\n",
    "        (\"g10_fact_inventory_movements_audit\", \"Build Fact Inventory Movements\", \"fact_inventory_movements\", \"Full audit trail\"),\n",
    "        (\"g11_agg_daily_inventory_summary\", \"Build Daily Inventory Summary\", \"agg_daily_inventory_summary\", \"Pre-aggregated for dashboards\"),\n",
    "        (\"g12_agg_product_performance_monthly\", \"Build Monthly Product Performance\", \"agg_product_performance_monthly\", \"Revenue rank, fill-rate, stockouts\"),\n",
    "        (\"g13_gold_inventory_alerts_realtime\", \"Generate Real-Time Alerts\", \"gold_inventory_alerts\", \"Low-stock, stockout, demand-spike\"),\n",
    "        (\"g14_gold_business_metrics_kpis\", \"Update Business KPIs\", \"gold_business_metrics\", \"Cancellation rate, sync latency, recovered revenue\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 4. Helper functions\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def create_directory(path):\n",
    "    \"\"\"Create a directory in the workspace\"\"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    data = {\"path\": path}\n",
    "    response = requests.post(\n",
    "        f\"{workspace_url}/api/2.0/workspace/mkdirs\",\n",
    "        headers=headers,\n",
    "        json=data\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(f\"✓ Directory created/verified: {path}\")\n",
    "    else:\n",
    "        print(f\"✗ Failed to create directory {path}: {response.text}\")\n",
    "    return response.status_code == 200\n",
    "\n",
    "def create_notebook(path, content):\n",
    "    \"\"\"Create a notebook in the workspace\"\"\"\n",
    "    import base64\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    \n",
    "    # Encode content to base64\n",
    "    content_bytes = content.encode('utf-8')\n",
    "    content_base64 = base64.b64encode(content_bytes).decode('utf-8')\n",
    "    \n",
    "    # Import the notebook (this creates it)\n",
    "    data = {\n",
    "        \"path\": path,\n",
    "        \"format\": \"SOURCE\",\n",
    "        \"language\": \"PYTHON\",\n",
    "        \"content\": content_base64,\n",
    "        \"overwrite\": True\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{workspace_url}/api/2.0/workspace/import\",\n",
    "        headers=headers,\n",
    "        json=data\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"✗ Failed to create {path}: {response.text}\")\n",
    "        return False\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 5. Create all notebooks\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "total_created = 0\n",
    "total_failed = 0\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GENERATING BRONZE/SILVER/GOLD NOTEBOOKS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create base directories\n",
    "for folder in [BASE, BRONZE, SILVER, GOLD]:\n",
    "    create_directory(folder)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Create notebooks\n",
    "for layer, items in NOTEBOOKS.items():\n",
    "    folder = BRONZE if layer == \"Bronze\" else SILVER if layer == \"Silver\" else GOLD\n",
    "    print(f\"\\n>>> Creating {len(items)} {layer} notebooks in {folder}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for fname, title, tables, desc in items:\n",
    "        notebook_path = f\"{folder}/{fname}\"\n",
    "        content = TEMPLATE.format(\n",
    "            title=title,\n",
    "            layer=layer,\n",
    "            tables=tables,\n",
    "            desc=desc,\n",
    "            ts=ts\n",
    "        )\n",
    "        \n",
    "        if create_notebook(notebook_path, content):\n",
    "            print(f\"✓ Created: {notebook_path}\")\n",
    "            total_created += 1\n",
    "        else:\n",
    "            print(f\"✗ Failed: {notebook_path}\")\n",
    "            total_failed += 1\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"✓ Successfully created: {total_created} notebooks\")\n",
    "if total_failed > 0:\n",
    "    print(f\"✗ Failed: {total_failed} notebooks\")\n",
    "print(f\"\\nNotebooks location: {BASE}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "generate_notebooks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
